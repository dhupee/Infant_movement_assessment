{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../src/data')\n",
    "sys.path.insert(0,'../src/modules')\n",
    "import load_pose_data\n",
    "import preprocess_pose_data\n",
    "import build_features\n",
    "import merge_data_sets\n",
    "import compute_surprise\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert video, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39massert\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(raw_pose_estimates_video_path), \u001b[39m'\u001b[39m\u001b[39mFolder does not exist. \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Edit path to pose estimate data (raw_pose_estimates_video_path) in notebooks/infant_move/master.ipynb, Cell 2.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     10\u001b[0m load_pose_data\u001b[39m.\u001b[39mmain(data_set, raw_pose_estimates_video_path)\n\u001b[0;32m---> 11\u001b[0m preprocess_pose_data\u001b[39m.\u001b[39;49mmain(data_set)\n\u001b[1;32m     12\u001b[0m build_features\u001b[39m.\u001b[39mmain(data_set)\n",
      "File \u001b[0;32m~/Projects/Infant_movement_assessment/notebooks/../src/data/preprocess_pose_data.py:37\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(data_set)\u001b[0m\n\u001b[1;32m     30\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdropna()\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39mvideo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbp\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mapply(\n\u001b[1;32m     31\u001b[0m     \u001b[39mlambda\u001b[39;00m x: smooth(x, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m, median_window, mean_window))\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     33\u001b[0m \u001b[39m# df = df.groupby(['video', 'bp']).apply(lambda x: smooth(x, 'y', median_window, mean_window)).reset_index(drop=True)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m# df = df.groupby(['video', 'bp']).apply(lambda x: smooth(x, 'x', median_window, mean_window)).reset_index(drop=True)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[39m# rotate and normalise by reference\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m xdf \u001b[39m=\u001b[39m normalise_skeletons(df)\n\u001b[1;32m     38\u001b[0m \u001b[39m# extract angles\u001b[39;00m\n\u001b[1;32m     39\u001b[0m adf \u001b[39m=\u001b[39m get_joint_angles(df)\n",
      "File \u001b[0;32m~/Projects/Infant_movement_assessment/notebooks/../src/modules/util_data.py:222\u001b[0m, in \u001b[0;36mnormalise_skeletons\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    216\u001b[0m h_angle \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39mvideo\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mapply(\n\u001b[1;32m    217\u001b[0m     \u001b[39mlambda\u001b[39;00m x: comp_joint_angle(x, \u001b[39m'\u001b[39m\u001b[39mHip\u001b[39m\u001b[39m'\u001b[39m))\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    219\u001b[0m \u001b[39m# s_angle = df.drop(columns=['video']).groupby(['video']).apply(lambda x: comp_joint_angle(x,'Shoulder')).reset_index()\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m# h_angle = df.drop(columns=['video']).groupby(['video']).apply(lambda x: comp_joint_angle(x,'Hip')).reset_index()\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m uref \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mvideo\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    223\u001b[0m     \u001b[39mlambda\u001b[39;49;00m x: comp_center_joints(x, \u001b[39m'\u001b[39;49m\u001b[39mShoulder\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39muref\u001b[39;49m\u001b[39m'\u001b[39;49m))\u001b[39m.\u001b[39;49mreset_index()\n\u001b[1;32m    224\u001b[0m lref \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39mvideo\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mapply(\n\u001b[1;32m    225\u001b[0m     \u001b[39mlambda\u001b[39;00m x: comp_center_joints(x, \u001b[39m'\u001b[39m\u001b[39mHip\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlref\u001b[39m\u001b[39m'\u001b[39m))\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m    227\u001b[0m s_angle[\u001b[39m'\u001b[39m\u001b[39mHip_angle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m h_angle[\u001b[39m'\u001b[39m\u001b[39mHip_angle\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/p6-infant/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/p6-infant/lib/python3.8/site-packages/pandas/core/frame.py:6358\u001b[0m, in \u001b[0;36mDataFrame.reset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[1;32m   6352\u001b[0m         \u001b[39mif\u001b[39;00m lab \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   6353\u001b[0m             \u001b[39m# if we have the codes, extract the values with a mask\u001b[39;00m\n\u001b[1;32m   6354\u001b[0m             level_values \u001b[39m=\u001b[39m algorithms\u001b[39m.\u001b[39mtake(\n\u001b[1;32m   6355\u001b[0m                 level_values, lab, allow_fill\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, fill_value\u001b[39m=\u001b[39mlev\u001b[39m.\u001b[39m_na_value\n\u001b[1;32m   6356\u001b[0m             )\n\u001b[0;32m-> 6358\u001b[0m         new_obj\u001b[39m.\u001b[39;49minsert(\n\u001b[1;32m   6359\u001b[0m             \u001b[39m0\u001b[39;49m,\n\u001b[1;32m   6360\u001b[0m             name,\n\u001b[1;32m   6361\u001b[0m             level_values,\n\u001b[1;32m   6362\u001b[0m             allow_duplicates\u001b[39m=\u001b[39;49mallow_duplicates,\n\u001b[1;32m   6363\u001b[0m         )\n\u001b[1;32m   6365\u001b[0m new_obj\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m new_index\n\u001b[1;32m   6366\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m inplace:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/p6-infant/lib/python3.8/site-packages/pandas/core/frame.py:4814\u001b[0m, in \u001b[0;36mDataFrame.insert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   4808\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   4809\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot specify \u001b[39m\u001b[39m'\u001b[39m\u001b[39mallow_duplicates=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4810\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mself.flags.allows_duplicate_labels\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is False.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4811\u001b[0m     )\n\u001b[1;32m   4812\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_duplicates \u001b[39mand\u001b[39;00m column \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns:\n\u001b[1;32m   4813\u001b[0m     \u001b[39m# Should this be a different kind of error??\u001b[39;00m\n\u001b[0;32m-> 4814\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcannot insert \u001b[39m\u001b[39m{\u001b[39;00mcolumn\u001b[39m}\u001b[39;00m\u001b[39m, already exists\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4815\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, \u001b[39mint\u001b[39m):\n\u001b[1;32m   4816\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mloc must be int\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert video, already exists"
     ]
    }
   ],
   "source": [
    "# Reference data: load, preprocess, kinematic features\n",
    "\n",
    "data_set = 'youtube'\n",
    "\n",
    "# raw_pose_estimates_video_path = '../data/pose_estimates/youtube/py/'\n",
    "raw_pose_estimates_video_path = '../colab_openpose/output_files'\n",
    "\n",
    "assert os.path.exists(raw_pose_estimates_video_path), 'Folder does not exist. \\n Edit path to pose estimate data (raw_pose_estimates_video_path) in notebooks/infant_move/master.ipynb, Cell 2.'\n",
    "\n",
    "load_pose_data.main(data_set, raw_pose_estimates_video_path)\n",
    "preprocess_pose_data.main(data_set)\n",
    "build_features.main(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/pose_estimates/clinical/py/pose_estimates.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39massert\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(raw_pose_estimates_video_path), \u001b[39m'\u001b[39m\u001b[39mFolder does not exist. \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Edit path to pose estimate data (raw_pose_estimates_video_path) in notebooks/infant_move/master.ipynb, Cell 3.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[39m# load_pose_data.main(data_set, raw_pose_estimates_video_path)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m preprocess_pose_data\u001b[39m.\u001b[39;49mmain(data_set)\n\u001b[1;32m     12\u001b[0m build_features\u001b[39m.\u001b[39mmain(data_set)\n",
      "File \u001b[0;32m~/Projects/Infant_movement_assessment/notebooks/../src/data/preprocess_pose_data.py:13\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(data_set)\u001b[0m\n\u001b[1;32m     11\u001b[0m mean_window \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     12\u001b[0m delta_window \u001b[39m=\u001b[39m \u001b[39m.25\u001b[39m  \u001b[39m# smoothing applied to delta_x, velocity, acceleration\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_pickle(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\n\u001b[1;32m     14\u001b[0m     pose_estimates_path, \u001b[39m'\u001b[39;49m\u001b[39mpose_estimates.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     15\u001b[0m \u001b[39m# normalise x and y by image length (conserve aspect ratio)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_numeric(df[\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/p6-infant/lib/python3.8/site-packages/pandas/io/pickle.py:190\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39m4    4    9\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m excs_to_catch \u001b[39m=\u001b[39m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m)\n\u001b[0;32m--> 190\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    191\u001b[0m     filepath_or_buffer,\n\u001b[1;32m    192\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    193\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    194\u001b[0m     is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    195\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    196\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m     \u001b[39m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[39m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[39m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         \u001b[39m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.16/envs/p6-infant/lib/python3.8/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    866\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/pose_estimates/clinical/py/pose_estimates.pkl'"
     ]
    }
   ],
   "source": [
    "# Clinical data: load, preprocess, kinematic features\n",
    "\n",
    "data_set = 'clinical'\n",
    "\n",
    "# raw_pose_estimates_video_path = '../data/pose_estimates/youtube/py/'\n",
    "raw_pose_estimates_video_path = '../colab_openpose/output_files'\n",
    "\n",
    "assert os.path.exists(raw_pose_estimates_video_path), 'Folder does not exist. \\n Edit path to pose estimate data (raw_pose_estimates_video_path) in notebooks/infant_move/master.ipynb, Cell 3.'\n",
    "\n",
    "# load_pose_data.main(data_set, raw_pose_estimates_video_path)\n",
    "preprocess_pose_data.main(data_set)\n",
    "build_features.main(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data sets and compute surprise based on features\n",
    "path = '../data/processed/'\n",
    "\n",
    "# merge youtube and clinical data sets\n",
    "merge_data_sets.main()\n",
    "\n",
    "# compute bayes surprise\n",
    "compute_surprise.main(path)\n",
    "\n",
    "# visualizations in notebooks/visualize_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pose estimation model: generate predictions from models in ../model folder\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "sys.path.insert(0,'../src/pose_model')\n",
    "import get_pose_model_predictions_and_groundtruth\n",
    "\n",
    "check_gpu_is_running =1\n",
    "if check_gpu_is_running==1:\n",
    "    print('CHECK GPU (look for output that mentions GPU)')\n",
    "    print(K.tensorflow_backend._get_available_gpus())\n",
    "    from tensorflow.python.client import device_lib\n",
    "    print(device_lib.list_local_devices())\n",
    "    # Creates a graph.\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "    # Creates a session with log_device_placement set to True.\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "    # Runs the op.\n",
    "    print(sess.run(c))\n",
    "\n",
    "get_pose_model_predictions_and_groundtruth.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6-infant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "52f84633204e1c9919a49a518f5ce72221b5710aac846630c087431dff22cdfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
